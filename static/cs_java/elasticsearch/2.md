### IK分词器
#### 1、解压IK插件并拷贝到： \\wsl.localhost\docker-desktop-data\data\docker\volumes\es-plugins\_data

#### 2、重启 docker restart es

#### 3、测试
```
    POST /_analyze
    {
      "analyzer": "standard",
      "text": "不积跬步无以至千里"
    }

    POST /_analyze
    {
      "analyzer": "ik_smart",
      "text": "不积跬步无以至千里"
    }
```

#### 4、拓展词典：
#### 4.1 修改 ik/config/IKAnalyzer.cfg.xml
```
    <?xml version="1.0" encoding="UTF-8"?>
    <!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
    <properties>
            <comment>IK Analyzer 扩展配置</comment>
            <!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典-->
            <entry key="ext_dict">ext.dic</entry>
            <!-- 用户可以在这里配置自己的扩展停止词字典 -->
            <entry key="ext_stopwords">stopword.dic</entry>
    </properties>
```

#### 4.2、config目录新建一个 ext.dic、stopword.dic
#### 5、docker restart es
#### 6、测试

#### 7、备注
```
    IK分词器有几种模式？

    - ik_smart：智能切分，粗粒度

    - ik_max_word：最细切分，细粒度
```
